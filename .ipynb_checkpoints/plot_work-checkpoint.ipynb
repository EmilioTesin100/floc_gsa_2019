{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook used to explore data in the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_pickle('/home/jovyan/floc_gsa_2019/regions_results_for_dep_5.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dep5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code used to explore raw floc size distribtion over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### (if you want to try to filter the data) for i, row in scene_windows[scene_windows.deployment == 5].iterrows():\n",
    "\n",
    "x_time = []\n",
    "y_stats = []\n",
    "results = pd.read_pickle('/home/jovyan/floc_gsa_2019/regions_results_for_dep_5.pickle')\n",
    "for i, row in results.iterrows():\n",
    "    for stats in row.label_stats:\n",
    "        x_time.append(row.datetime)\n",
    "        y_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_results = pd.DataFrame({'x_time': x_time, 'y_stats': y_stats})\n",
    "regions_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(regions_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = [len(i) for i in results.label_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_floc = results['label_stats'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(total_floc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv.Histogram(frequencies, edges, extents=(0.002, None, 0.016, None))\n",
    "import hvplot \n",
    "regions_results.hvplot.scatter(x='x_time', y='y_stats', dynspread=True, datashade=True, width=720, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, math\n",
    "import matplotlib.dates as dates\n",
    "import hvplot.pandas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.rc('font', size=11)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18, 6)\n",
    "fig.frameon = False\n",
    "hb1 = ax.hexbin(regions_results.x_time, regions_results.y_stats, vmin=0, vmax=1.25, bins='log', linewidths=0.25,\n",
    "  gridsize=(200, 80), mincnt=1, cmap=plt.cm.BuPu)\n",
    "fig.colorbar(hb1)\n",
    "ax.set_ylim([0, 1400])\n",
    "ax.set_xlim([datetime.date(2018, 7, 1), datetime.date(2019, 2, 10)])\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "months = dates.MonthLocator()  #Months\n",
    "monthsFmt = dates.DateFormatter('%m %Y')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "plt.ylabel('Number of Floc Particles');\n",
    "plt.savefig('test_jan_2019_hexbin.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_value = 1000; # this is an arbitrary value that we are using to explore the data\n",
    "number_floc = results_dep5.nflocs\n",
    "label_statistics = results_dep5.Label_stats\n",
    "\n",
    "def value_thresh(label_statistics, number_floc, defined_value):\n",
    "    I_filt = frame_filter(frame, d1, d2, n)\n",
    "    I_thresh = np.array(np.absolute(I_filt)>threshold)\n",
    "    return I_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrap work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_volume = []\n",
    "def frame_volume_func(results_dep5):\n",
    "    label_stats = label_stats(results_dep5)\n",
    "    for i in results_dep5.label_stats:\n",
    "        frame_volume.append((I_labeled==i).sum())\n",
    "    return frame_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dep5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for i, row in results_dep5[scene_windows.deployment == 5].iterrows():\n",
    "\n",
    "frame_volume = []\n",
    "\n",
    "results_dep5 = pd.read_pickle('/home/jovyan/floc_gsa_2019/regions_results_for_dep_5.pickle')\n",
    "for i, row in results_dep5.iterrows():\n",
    "    for frame_volume in row.label_stats:\n",
    "        url.append(row.url)\n",
    "        frame_volume = [results_dep5.label_stats == row.url].iloc[0] + frame_number/29.97\n",
    "        frame_volumes.append(frame_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_volumes = []\n",
    "results_dep5 = pd.read_pickle('/home/jovyan/floc_gsa_2019/regions_results_for_dep_5.pickle')\n",
    "for i, label_stats in enumerate(results_dep5.label_stats):\n",
    "    frame_volumes.append(sum(results_dep5.label_stats)\n",
    "frame_volume.append(frame_volumes)\n",
    "results_dep5.head()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_volumes = []\n",
    "for i, label_stats in enumerate(results_dep5.label_stats):\n",
    "    frame_volumes.append(sum(results_dep5.label_stats)\n",
    " return frame_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #results_dep5['frame_volume'] = frame_volume\n",
    "#results_dep5.head()     \n",
    "    # #######[i for i in l if isinstance(i, int) or isinstance(i, float)])\n",
    "frame_interval = 69\n",
    "window_buffer = 10\n",
    "frame_lists = []\n",
    "for i, start_frame in enumerate(scene_windows.start_frame):\n",
    "    frame_lists.append(list(range(start_frame+window_buffer, scene_windows.end_frame[i]-window_buffer, frame_interval)))\n",
    "scene_windows['frame_list'] = frame_lists\n",
    "scene_windows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "frame_datenum = []\n",
    "frame_datetime = []\n",
    "# nflocs = [len(i) for i in label_stats]\n",
    "frame_numbers = []\n",
    "dbcamhd = pd.read_json('/home/jovyan/floc_gsa_2019/dbcamhd.json', orient=\"records\", lines=True)\n",
    "for i, row in scene_windows[scene_windows.deployment == 5].iterrows():\n",
    "    for frame_number in row.frame_list:\n",
    "        url.append(row.url)\n",
    "        frame_epoch_seconds = dbcamhd['timestamp'][dbcamhd.filename == row.url].iloc[0] + frame_number/29.97\n",
    "        frame_datetime.append(datetime.datetime.fromtimestamp(frame_epoch_seconds))\n",
    "        frame_datenum.append(dates.date2num(frame_datetime[-1]))\n",
    "        frame_numbers.append(frame_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a thresholded binary image as input\n",
    "def frame_label_stats(I_thresh):\n",
    "    I_labeled = label(I_thresh)\n",
    "    label_stats = []\n",
    "    for i in range(1, I_labeled.max()+1):\n",
    "        label_stats.append((I_labeled==i).sum())\n",
    "    return label_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dep5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find lines with observed floc values greater than a defined value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4000\n",
    "movie_list = []\n",
    "\n",
    "for i, row in enumerate(results.label_stats):\n",
    "    if any(j > n for j in row):\n",
    "        ## movie_list.append(results_dep5.url.loc(i))\n",
    "        movie_list.append(results.loc[i].url)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.loc(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4000\n",
    "movie_list = []\n",
    "for i, row in results_dep5[results_dep5.label_stats > 2000 ].iterrows():\n",
    "    movie_list = row.label_stats\n",
    "    \n",
    "    filename = row.url\n",
    "    delayed_moov_atom = delayed(get_moov_atom_timeout)(filename)\n",
    "    for frame_number in row.frame_list:\n",
    "        delayed_frame = delayed(get_frame_timeout)(filename, frame_number, 'gray16le', delayed_moov_atom)\n",
    "        delayed_frame_thresh = delayed(frame_thresh)(delayed_frame, d1, d2, n, threshold)\n",
    "        delayed_label_stats.append(delayed(frame_label_stats)(delayed_frame_thresh))\n",
    "delayed_label_stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
